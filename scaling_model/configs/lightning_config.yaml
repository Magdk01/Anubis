seed: 42069420
experiment: new_dataset_aggr_fixed_1000_atoms_we_go_agane

sampler: 
  sampler_type: random
  sampling_prob: 0.5

data:
  target: 0
<<<<<<< HEAD
  data_dir: scraped_data_1000_new_5_${sampler}/
  max_protein_size: 1000
  batch_size_train: 4
=======
  data_dir: data_300/
  max_protein_size: 10000
  batch_size_train: 2
>>>>>>> f520e3cde18163bb4cea1f7ded846fa460b46a16
  batch_size_inference: 1
  num_workers: 11
  splits: [0.8, 0.1, 0.1]
  seed: ${seed}
  subset_size: null
  random_data: false


lightning_model:
  ema_decay: 0.9
  painn_kwargs:
    num_message_passing_layers: 3
    num_features: 128
    num_rbf_features: 20
    num_unique_atoms: 100
    cutoff_dist: 5.0
  prediction_kwargs:
    num_features: ${lightning_model.painn_kwargs.num_features}
    num_layers: 2
  optimizer_kwargs:
    weight_decay: 0.01
    lr: 1e-4
  lr_scheduler_kwargs:
    mode: min
    factor: 0.5
    patience: 5
    threshold: 1e-6
    threshold_mode: rel
    cooldown: 2
    min_lr: 1e-6

early_stopping:
    monitor: ema_val_loss
    patience: 30
    min_delta: 1e-6

model_checkpoint:
    filename: ${experiment}_${logger.name}_{epoch}_{val_loss:.6f}
    save_top_k: 1
    verbose: false
    monitor: val_loss
    mode: min

trainer:
<<<<<<< HEAD
  max_epochs: 10
  max_time: 00:08:00:00
=======
  max_epochs: 1
  max_time: 02:23:30:00
>>>>>>> f520e3cde18163bb4cea1f7ded846fa460b46a16
  deterministic: true

logger:
  save_dir: logs/${now:%Y-%m-%d_%H-%M-%S}
<<<<<<< HEAD
  project: HPC_benchmarks
  name: mvin_${experiment}_batch_${data.batch_size_train}_layers_${lightning_model.painn_kwargs.num_message_passing_layers}_sampler_${sampler}_time_${now:%Y-%m-%d_%H-%M-%S}
=======
  project: debugging
  name: ehaa_sampling_experiments_time_${now:%Y-%m-%d_%H-%M-%S}
>>>>>>> f520e3cde18163bb4cea1f7ded846fa460b46a16
  entity: anubis
  dir: /zhome/16/a/167936/Desktop/Bachelor/Anubis