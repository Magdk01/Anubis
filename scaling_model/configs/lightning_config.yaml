seed: 0
experiment: painn_qm9

data:
  target: 0
  data_dir: data/
  batch_size_train: 1
  batch_size_inference: 1
  num_workers: 0
  splits: [5, 2, 2]
  seed: ${seed}
  subset_size: null

lightning_model:
  ema_decay: 0.9
  painn_kwargs:
    num_message_passing_layers: 3
    num_features: 128
    num_rbf_features: 20
    num_unique_atoms: 100
    cutoff_dist: 5.0
  prediction_kwargs:
    num_features: ${lightning_model.painn_kwargs.num_features}
    num_layers: 2
  optimizer_kwargs:
    weight_decay: 0.01
    lr: 5e-4
  lr_scheduler_kwargs:
    mode: min
    factor: 0.5
    patience: 5
    threshold: 1e-6
    threshold_mode: rel
    cooldown: 2
    min_lr: 1e-6

early_stopping:
    monitor: ema_val_loss
    patience: 30
    min_delta: 1e-6

model_checkpoint:
    filename: ${experiment}_${logger.name}_{epoch}_{val_loss:.6f}
    save_top_k: 1
    verbose: false
    monitor: val_loss
    mode: min

trainer:
  max_epochs: 100000
  max_time: 00:23:30:00
  deterministic: true

logger:
    save_dir: logs/${experiment}
    name: default
    default_hp_metric: false